---
layout: article
title:  "细粒度识别论文阅读《Weakly Supervised Complementary Parts Models for Fine-Grained Image Classification from the Bottom Up》"
date:   2019-11-21 09:53:48 +0000
tags: Fine-grained
mathjax: true
mathjax_autoNumber: true
---



## 任务


细粒度识别，弱监督信息下识别子类分类问题，例如分辨不同鸟、车、飞机。  



## 出发点

<!-- 细粒度的识别难点在于网络很难从一个固定分辨率大小的图中自适应的找到合适分类的纹理特征，该论文通过放大图像中的纹理特征以期望获得网络的关注（在分类上更有权重）。 -->

图像分类任务往往关注最具有辨别特征的区域，而对其他有信息量的区域的关注度不够。
在细粒度图像识别任务中，最具判别性的区域往往对于分类信息是不足的。
该文章提取使用弱监督的下的目标定位进行数据集增强，提出stack lstm进行多图的特征融合，大幅地提高了细粒度的识别准确率。



## 难点

1. 如何进行目标定位？
2. 如何进行辅助图像的利用？


## 方法

### 网络总览

1. 使用标签信息进行目标定位，使用mask-rcnn的方式，提取目标的多个候选框。
2. 使用搭建的CNN + Stack LSTM，提取并融合多图的特征。


<figure>
<a><img src="{{site.url}}/assert/wscpm_all.png"></a>
</figure>
<!-- As an analogy [15] to natural language processing, shuffling
words in a sentence would force the neural network to focus
on discriminative words and neglect irrelevant ones. Similarly, if local regions in an image are “shuffled”, the neural
network would be forced to learn from discriminative region details for classification. -->

**Bilinear Attention Pooling**

<!-- ![navigate](assert/navigate.png) -->

就是一般的bilinear pooling，两流的输入，一流为特征图，另一流为attention图。

设 $$ X = N * H * W  -> reshape -> X = N * HW $$, $$ A = M * H * W -> reshape -> A = M * HW $$，
则bilinear输出定义为：

$$ B = XA^T $$

所以得到$$B$$的shape为$$(N,M)$$。



<!-- $$a=\frac{1}{1+sin(x)}$$ -->

<!-- ![](http://latex.codecogs.com/gif.latex?\\a=\frac{1}{1+sin(x)}) -->



**Attention Cropping**

从InceptionV3的某一层获取卷积层输出，使用1*1卷积获取attention图。

将attention按照通道维度平均池化，获得总的全局attention图。根据全局attention图裁剪得到目标图。

裁剪的方法参见论文[《Learning deep features for discriminative localization》](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf)


裁剪的理解：attention图的按照最大连通域裁剪

做法，取最大值的20%为阈值，计算最大连通域，裁剪最大连通域的矩形框。

参考做法


    import cv2
    import os
    import numpy as np

    from skimage.morphology import label
    from skimage.measure import regionprops


    img_path = '/root/skb/inception_bili/images.jpg'

    img = cv2.imread(img_path,0)

    print(img.max())



    max_value = np.max(img)




    ret, ee = cv2.threshold(img, 0.8*max_value, max_value, cv2.THRESH_BINARY)

    cv2.imwrite('/root/skb/inception_bili/ee.png',ee)

    labeled_img, num = label(ee, neighbors=4, background=0, return_num=True)

    # minr, minc, maxr, maxc = regionprops(labeled_img)[max_label].bbox

    max_area = -1
    for region in regionprops(labeled_img):
        # skip small images
        if region.area < 50:
            continue
        if region.area > max_area:
        #print(regionprops(labeled_img)[max_label])
            max_area = region.area
            minr, minc, maxr, maxc = region.bbox

    crop_img = img[minr:maxr,minc:maxc]
    cv2.imwrite('/root/skb/inception_bili/crop.png',crop_img)

    print(ret,ee)




<!-- <img class="image image--lg" src="{{site.url}}/assert/tasn_ab.png"/> -->

**loss设计**

两阶段的图像分类loss和attention图的中心loss

## **RESULT**

<!-- ![result](assert/result.png) -->

<figure>
<a><img src="{{site.url}}/assert/wsban_result.png"></a>
</figure>



[原文链接《Weakly Supervised Bilinear Attention Network for Fine-Grained Visual Classification》](https://arxiv.org/pdf/1808.02152.pdf)
