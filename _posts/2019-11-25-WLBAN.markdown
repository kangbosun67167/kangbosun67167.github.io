---
layout: article
title:  "细粒度识别论文阅读《Weakly Supervised Bilinear Attention Network for Fine-Grained Visual Classification》"
date:   2019-11-21 09:53:48 +0000
tags: Fine-grained
mathjax: true
mathjax_autoNumber: true
---



## 任务


细粒度识别，弱监督信息下识别子类分类问题，例如分辨不同鸟、车、飞机。  



## 出发点

<!-- 细粒度的识别难点在于网络很难从一个固定分辨率大小的图中自适应的找到合适分类的纹理特征，该论文通过放大图像中的纹理特征以期望获得网络的关注（在分类上更有权重）。 -->

细粒度识别领域常常采用弱监督信息进行目标定位，然而误检和遮挡会导致目标定位发生较大的偏差，一定程度上引起推断的波动性（即学习过程不稳定）和损害准确率的增长。
作者从attention角度出发，对特征图进行attention量化，实现另一种形式的目标定位，two-stage的方式进一步提取裁剪图片的特征进行联合分类。







## 难点

1. attention图如何产生？
2. 特征图和attention图搭配使用？
3. 如何使用attention图进行裁剪？  
<!-- 3. 如何？ -->


## 方法

### 网络总览

1. 原图经过InceptionV3特征提取产生特征图，其中使用1*1卷积产生attention图(128维度)，将attention图和特征图进行bilinear汇合，称之为bilinear attention pooling（BAP）。最后进行提取出相应的特征。
2. attention图进行通道间的平均加权，使用论文[《Learning deep features for discriminative localization》](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf)
中的方法进行裁剪，得到目标裁剪图。
3. 裁剪图如1中的过程得到特征，最后与原图特征联合分类。


<figure>
<a><img src="{{site.url}}/assert/wsban_all.png"></a>
</figure>
<!-- As an analogy [15] to natural language processing, shuffling
words in a sentence would force the neural network to focus
on discriminative words and neglect irrelevant ones. Similarly, if local regions in an image are “shuffled”, the neural
network would be forced to learn from discriminative region details for classification. -->

**Bilinear Attention Pooling**

<!-- ![navigate](assert/navigate.png) -->

就是一般的bilinear pooling，两流的输入，一流为特征图，另一流为attention图。

设 $$ X = N * H * W  -> reshape -> X = N * HW $$, $$ A = M * H * W -> reshape -> A = M * HW $$，
则bilinear输出定义为：

$$ B = XA^T $$

所以得到$$B$$的shape为$$(N,M)$$。



<!-- $$a=\frac{1}{1+sin(x)}$$ -->

<!-- ![](http://latex.codecogs.com/gif.latex?\\a=\frac{1}{1+sin(x)}) -->



**Attention Sampling**

从InceptionV3的某一层获取卷积层输出，使用1*1卷积获取attention图。

将attention按照通道维度平均池化，获得总的全局attention图。根据全局attention图裁剪得到目标图。

裁剪的方法参见论文[《Learning deep features for discriminative localization》](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf)



<!-- <img class="image image--lg" src="{{site.url}}/assert/tasn_ab.png"/> -->

**loss设计**

part网络的的fc输出经过带T的‘softmax’激活作为master的一个标签（用作知识蒸馏）。

最后master网络同时使用类别交叉熵和与part网络输出的交叉熵，part网络使用类别交叉熵训练。


## **RESULT**

<!-- ![result](assert/result.png) -->

<figure>
<a><img src="{{site.url}}/assert/tasn_result.png"></a>
</figure>



[原文链接《Weakly Supervised Bilinear Attention Network for Fine-Grained Visual Classification》](https://arxiv.org/pdf/1808.02152.pdf)
